# Frequently Asked Questions (FAQs)

This section provides answers to frequently asked questions about GPT-4 with Vision (GPT-4V).

## Can I fine-tune GPT-4V's image capabilities?

Currently, fine-tuning GPT-4V's image capabilities is not supported. The model is pre-trained and does not allow for additional training on specific tasks.

## Can GPT-4V generate images?

No, GPT-4V cannot generate images. Its primary function is to interpret and answer questions about images.

## What file types are supported by GPT-4V?

GPT-4V supports PNG, JPEG, WEBP, and non-animated GIF files.

## Is there a size limit for image uploads?

Yes, image uploads are restricted to 20MB per image.

## How are images processed in terms of rate limits?

Images are processed at the token level and count towards the total tokens per minute (TPM) limit.

## How does GPT-4V handle non-Latin text and small text in images?

GPT-4V may struggle with non-Latin text and small text in images. The model's performance in these areas is an active area of research and development.

## Can GPT-4V interpret rotated images?

GPT-4V may have difficulty interpreting rotated images. It is recommended to provide images in their correct orientation for optimal results.

## Can GPT-4V be used for specialized tasks like interpreting medical images?

GPT-4V is not suitable for specialized tasks like interpreting medical images. It is designed for general image interpretation tasks.

## How are images charged in terms of tokens?

Images are charged in tokens based on their size and the detail level chosen for processing. The larger the image and the higher the detail level, the more tokens are used.

For more detailed information about the capabilities, limitations, and considerations of GPT-4V, please refer to the respective markdown files in this repository.

