# GPT-4 with Vision (GPT-4V)

GPT-4 with Vision (GPT-4V) is an extension of OpenAI's GPT-4 model, enabling it to interpret images along with text. This repository provides a comprehensive guide on how to utilize this feature.

## Table of Contents

1. [Introduction to GPT-4 with Vision (GPT-4V)](introduction_to_gpt4v.md)
2. [Quick Start Guide](quick_start_guide.md)
3. [Uploading Base64 Encoded Images](uploading_base64_encoded_images.py)
4. [Handling Multiple Image Inputs](handling_multiple_image_inputs.py)
5. [Detail Levels in Image Understanding](detail_levels_in_image_understanding.md)
6. [Managing Images](managing_images.md)
7. [Limitations and Considerations](limitations_and_considerations.md)
8. [FAQs](faqs.md)

## Overview

GPT-4V can process images and answer questions about them, expanding beyond the text-only input limitation. It is available to all developers with GPT-4 access via the gpt-4-vision-preview model in the Chat Completions API.

## Getting Started

To get started with GPT-4V, refer to the [Quick Start Guide](quick_start_guide.md). This guide provides a step-by-step process on how to pass images via links or as base64 encoded directly in the request.

## Examples

This repository includes Python scripts demonstrating how to encode and upload a local image ([uploading_base64_encoded_images.py](uploading_base64_encoded_images.py)) and how to handle multiple images ([handling_multiple_image_inputs.py](handling_multiple_image_inputs.py)).

## More Information

For more detailed information about the capabilities, limitations, and considerations of GPT-4V, please refer to the respective markdown files in this repository.

## FAQs

For frequently asked questions about GPT-4V, refer to the [FAQs](faqs.md) section.

## License

This project is licensed under the terms of the MIT license.
